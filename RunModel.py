import os
import numpy as np
import AD2SD
import data_processor as dp
from my_models import My_XGBoost  # ç›®å‰åªç”¨ XGBoostï¼Œä¹‹å¾Œæœ‰éœ€è¦å†æ“´å……
import plotting_utils as pltUT
import gc
import pandas as pd
import psutil


# =========================================================
# è³‡æ–™å‰è™•ç†ï¼šAD + IOLag â†’ SD.xlsx
# =========================================================
def data_preprocess(DATA_FOLDER, IPnum, DeltaT):
    """
    ä¾ç…§ä½ çš„åŸæœ¬è³‡æ–™å¤¾çµæ§‹ï¼ŒæŠŠ AD.xlsx + IOLag.xlsx è½‰æˆ SD.xlsx
    è·¯å¾‘ä¾‹å¦‚ï¼šDATA/IP01-1/AD.xlsx, IOLag.xlsx â†’ SD.xlsx
    """
    AD_FILE    = DATA_FOLDER + 'IP0' + IPnum + '-' + DeltaT + '/AD.xlsx'
    IOLAG_FILE = DATA_FOLDER + 'IP0' + IPnum + '-' + DeltaT + '/IOLag.xlsx'
    SD_FILE    = DATA_FOLDER + 'IP0' + IPnum + '-' + DeltaT + '/SD.xlsx'

    ADevents = AD2SD.read_AD(AD_FILE)
    iolag    = AD2SD.read_IOLag(IOLAG_FILE)
    sd       = AD2SD.ad2sd(ADevents, iolag)
    AD2SD.write_SD(ADevents, sd, SD_FILE)

    return SD_FILE


# =========================================================
# å…§éƒ¨å·¥å…·ï¼šç”¨ AD.xlsx æ±ºå®šè¦ä¸è¦è·³éäº‹ä»¶
# =========================================================
def _build_skip_mask_from_AD(sd_file, events):
    """
    å›å‚³ skip_maskï¼šTrue è¡¨ç¤ºè©²äº‹ä»¶ Depth å…¨ç‚º -1ï¼Œè¦è·³éã€‚
    äº‹ä»¶æ•¸é‡å¤šå°‘éƒ½å¯ä»¥ï¼Œè·Ÿ 10 å ´ / 7 å ´ç„¡é—œã€‚
    """
    ad_folder = os.path.dirname(sd_file)
    ad_file   = os.path.join(ad_folder, "AD.xlsx")

    skip_mask = []
    if os.path.isfile(ad_file):
        xls_ad = pd.ExcelFile(ad_file)
        for sheet in xls_ad.sheet_names:
            df_ad = pd.read_excel(ad_file, sheet_name=sheet)
            df_ad.columns = df_ad.columns.astype(str).str.strip()
            if "Depth (cm)" in df_ad.columns:
                depth = pd.to_numeric(df_ad["Depth (cm)"], errors="coerce")
                # è©²äº‹ä»¶æ‰€æœ‰ Depth éƒ½æ˜¯ -1ï¼ˆæˆ– NaN â†’ å¡«æˆ -1ï¼‰å°±è·³é
                flag_all_minus1 = depth.notna().size > 0 and (depth.fillna(-1) == -1).all()
                skip_mask.append(flag_all_minus1)
            else:
                # æ²’æœ‰ Depth æ¬„ â†’ ä¸è·³ï¼ˆä¿å®ˆè™•ç†ï¼‰
                skip_mask.append(False)
    else:
        # æ‰¾ä¸åˆ° AD.xlsx â†’ å…¨éƒ¨ä¸è·³
        skip_mask = [False] * len(events)

    # ä¿éšªï¼šé•·åº¦ä¸å°å°±å…¨éƒ¨ä¸è·³
    if len(skip_mask) != len(events):
        skip_mask = [False] * len(events)

    return skip_mask


# =========================================================
# å…§éƒ¨å·¥å…·ï¼šæ ¹æ“š boundary ç”¢ç”Ÿ PrevDepthï¼ˆä¸è·¨é¢±é¢¨ï¼‰
# =========================================================
def _build_prev_depth_per_sample(Y_flat, boundary_list):
    """
    Y_flat: shape (num_samples,) çš„çœŸå¯¦æ°´æ·±
    boundary_list: ä¾‹å¦‚ [len(ev1), len(ev1)+len(ev2), ...]
    å›å‚³ prev_depth_flat: åŒæ¨£ shape (num_samples,)
      - æ¯å€‹äº‹ä»¶çš„ç¬¬ä¸€å€‹æ¨£æœ¬ prev_depth = 0
      - ä¹‹å¾Œ prev_depth(i) = Y_flat(i-1)ï¼ˆåŒä¸€äº‹ä»¶å…§ï¼‰
    """
    num_samples = len(Y_flat)
    prev_depth = np.zeros_like(Y_flat, dtype=np.float32)

    start = 0
    for b in boundary_list:
        end = b  # [start, end) æ˜¯åŒä¸€äº‹ä»¶
        if end > start:
            # è©²äº‹ä»¶ç¬¬ä¸€ç­† â†’ 0ï¼ˆä¿æŒ 0ï¼‰
            # å¾Œé¢æ¯ä¸€ç­† = å‰ä¸€ç­† Y
            prev_depth[start + 1:end] = Y_flat[start:end - 1]
        start = end

    return prev_depth


# =========================================================
# ä¸»æ¨¡å‹å»ºæ§‹ï¼‹äº¤å‰é©—è­‰
# =========================================================
def ConstructModel(
    SD_FILE,
    OUTPUT_FOLDER,
    HYDROGRAPH_FOLDER,
    SCATTER_PLOT_FOLDER,
    WEIGHTS_FOLDER,
    epochs, batch_size, lr, loss_fn,
    dropout_rate, units, num_layers,
    bpnn_hidden_units, bpnn_learning_rate,
    svm_kernel, svm_C, svm_epsilon,
    cnn_dropout_rate, cnn_filters_1, cnn_filters_2, cnn_dense_units,
    DeltaT,
    use_autoreg=False,
):
    """
    é€™è£¡åšçš„äº‹ï¼š
    1. è®€ SD.xlsx â†’ events (list of DataFrame)ï¼Œæ¯å€‹ sheet ä¸€å€‹äº‹ä»¶
    2. æ ¹æ“š AD.xlsx æ±ºå®šè¦è·³éå“ªäº›äº‹ä»¶ï¼ˆDepth å…¨ -1ï¼‰
    3. åšã€Œäº‹ä»¶ç´šäº¤å‰é©—è­‰ã€ï¼šæ¯ä¸€æŠ˜æŠŠæœ€å¾Œä¸€å€‹äº‹ä»¶ç•¶ testï¼Œå…¶é¤˜ç•¶ train
    4. å¦‚æœ use_autoreg=Trueï¼š
       - è¨“ç·´æ™‚ï¼šPrevDepth = åŒä¸€äº‹ä»¶å…§å‰ä¸€ç­†çœŸå¯¦æ°´æ·±
       - æ¸¬è©¦æ™‚ï¼šPrevDepth = æ¨¡å‹ä¸Šä¸€æ™‚é–“æ­¥çš„é æ¸¬å€¼ï¼ˆè‡ªå›æ­¸ï¼‰
    5. å›å‚³ï¼š
       - Y_first_fold: ç¬¬ä¸€æŠ˜çš„ Y åºåˆ—
       - boundaries  : æ¯ä¸€æŠ˜çš„ boundary
       - RES_train / RES_test: å„æŠ˜çš„ (è§€æ¸¬, é æ¸¬)
       - events, event_orders: æœ€çµ‚ä¸€æ¬¡è¿­ä»£çš„äº‹ä»¶å…§å®¹èˆ‡é †åº
    """

    # -----------------------------------------------------
    # 1. è¼‰å…¥ SD.xlsx â†’ eventsï¼ˆlist of DataFrameï¼‰
    # -----------------------------------------------------
    events = dp.load_data(SD_FILE)

    # ç”¨ AD.xlsx æ±ºå®šå“ªäº›äº‹ä»¶è¦è·³éï¼ˆDepth å…¨ -1ï¼‰
    skip_mask = _build_skip_mask_from_AD(SD_FILE, events)

    filtered_events = []
    for ev, skip in zip(events, skip_mask):
        if not skip:
            filtered_events.append(ev)

    if len(filtered_events) == 0:
        raise ValueError("AD.xlsx ä¸­æ‰€æœ‰äº‹ä»¶çš„ Depth (cm) çš†ç‚º -1ï¼Œç„¡å¯è¨“ç·´ä¹‹äº‹ä»¶ã€‚")

    events = filtered_events
    num_events = len(events)

    # ä¿ç•™åŸæœ¬äº‹ä»¶ç·¨è™Ÿï¼ˆ1-basedï¼‰
    event_order = []
    for idx, skip in enumerate(skip_mask):
        if not skip:
            event_order.append(idx + 1)

    # -----------------------------------------------------
    # 2. äº¤å‰é©—è­‰éœ€è¦è¨˜éŒ„çš„æ±è¥¿
    # -----------------------------------------------------
    boundaries   = []   # æ¯ä¸€æŠ˜å°æ‡‰çš„ boundaryï¼ˆç´¯ç©é•·åº¦ï¼‰
    event_orders = []   # æ¯ä¸€æŠ˜çš„äº‹ä»¶é †åº
    RES_train    = []   # æ¯ä¸€æŠ˜è¨“ç·´é›† [obv, est]
    RES_test     = []   # æ¯ä¸€æŠ˜æ¸¬è©¦é›† [obv, est]

    # ç”¨ä¾†å›å‚³çµ¦å¤–é¢çš„ Yï¼ˆæ­é… boundaries[0] ä½¿ç”¨ï¼‰
    Y_first_fold = None

    # =====================================================
    # 3. äº¤å‰é©—è­‰ï¼šæ¯ä¸€æŠ˜è¼ªæµæ‹¿æœ€å¾Œä¸€å€‹äº‹ä»¶ç•¶ test
    #    num_events å¯å¤§å¯å°ï¼Œè·Ÿ 10 å ´æ²’é—œä¿‚
    # =====================================================
    for ev_idx in range(num_events):

        # -------------------------------------------------
        # 3-1. é‡æ–°æ’åºäº‹ä»¶ï¼æ±ºå®š train/test åˆ‡é»
        # -------------------------------------------------
        events, event_order, boundary, split_boundary = dp.reorder_events(events, event_order)
        event_orders.append(event_order)
        boundaries.append(boundary)

        # -------------------------------------------------
        # 3-2. ç”¢ç”Ÿ X_raw, Y_rawï¼ˆå°šæœªæ­£è¦åŒ–ï¼‰
        # -------------------------------------------------
        # X_raw: (samples, num_features, 1)
        # Y_raw: (samples, 1)
        X_raw, Y_raw = dp.create_sequences(events)
        Y_raw_vec = Y_raw.reshape(-1)   # (samples,)

        # ç¬¬ä¸€æŠ˜çš„ Y + boundary æœƒè¢« get_eventWithMaxVal ä½¿ç”¨
        if ev_idx == 0:
            Y_first_fold = Y_raw_vec.copy()

        num_samples = X_raw.shape[0]

        # å…±ç”¨çš„ã€ŒåŸºç¤ç‰¹å¾µã€ï¼ˆä¸åŒ…å« PrevDepthï¼‰ï¼Œæ”¤å¹³æˆ (samples, D_base)
        X_base_flat = X_raw.reshape(num_samples, -1)

        # -------------------------------------------------
        # 3-3. å¦‚æœæœ‰å•Ÿç”¨è‡ªå›æ­¸ï¼šå…ˆç®—ã€ŒçœŸå¯¦å‰ä¸€æ ¼æ°´æ·±ã€ï¼ˆç”¨ä¾†è¨“ç·´ï¼‰
        # -------------------------------------------------
        if use_autoreg:
            print("âš™ å•Ÿç”¨è‡ªå›æ­¸ç‰¹å¾µï¼ˆè¨“ç·´ï¼‰ï¼šPrevDepth = åŒä¸€é¢±é¢¨äº‹ä»¶å…§å‰ä¸€ç­†çœŸå¯¦æ°´æ·±ï¼ˆé¦–ç­† = 0ï¼‰")
            prev_depth_full = _build_prev_depth_per_sample(Y_raw_vec, boundary)
        else:
            prev_depth_full = None

        # -------------------------------------------------
        # 3-4. åœ¨ã€ŒåŸå§‹å°ºåº¦ã€åˆ‡å‡º train / test
        # -------------------------------------------------
        X_train_base = X_base_flat[:split_boundary]      # (N_train, D_base)
        Y_train_raw  = Y_raw_vec[:split_boundary]        # (N_train,)

        X_test_base  = X_base_flat[split_boundary:]      # (N_test, D_base)
        Y_test_raw   = Y_raw_vec[split_boundary:]        # (N_test,)

        if use_autoreg:
            prev_train = prev_depth_full[:split_boundary]    # (N_train,)
        else:
            prev_train = None

        # -------------------------------------------------
        # 3-5. å»ºç«‹ã€Œè¨“ç·´ç”¨ç‰¹å¾µçŸ©é™£ã€ï¼šX_train_with_prev
        # -------------------------------------------------
        if use_autoreg:
            prev_train_col = prev_train.reshape(-1, 1)       # (N_train, 1)
            X_train_with_prev = np.concatenate([X_train_base, prev_train_col], axis=1)
        else:
            X_train_with_prev = X_train_base

        # -------------------------------------------------
        # 3-6. åªç”¨ã€Œè¨“ç·´è³‡æ–™ã€ç®— min/maxï¼Œå†ç¸®æ”¾ train
        # -------------------------------------------------
        X_train_final = X_train_with_prev
        Y_train = Y_train_raw.reshape(-1)
        Y_test  = Y_test_raw.reshape(-1)

        # -------------------------------------------------
        # 3-7. å»ºç«‹æ¬Šé‡æª”å„²å­˜è·¯å¾‘
        # -------------------------------------------------
        if not os.path.exists(WEIGHTS_FOLDER):
            os.makedirs(WEIGHTS_FOLDER, exist_ok=True)

        weights_path = os.path.join(
            WEIGHTS_FOLDER,
            'Weights_EV' + "%02d" % (ev_idx + 1) + '.h5'
        )

        # =================================================
        # 4. è¨“ç·´ XGBoost æ¨¡å‹
        # =================================================
        print('\n[ç¬¬ %d/%d æ¬¡è¨“ç·´]' % (ev_idx + 1, num_events))
        print(
            'â–¶ ä»¥ç¬¬ '
            + ', '.join(str(x) for x in sorted(event_order[:-1]))
            + ' å ´äº‹ä»¶ç‚ºè¨“ç·´è³‡æ–™ï¼Œä»¥ç¬¬ '
            + str(event_order[-1])
            + ' å ´äº‹ä»¶ç‚ºæ¸¬è©¦è³‡æ–™\n'
        )

        model = My_XGBoost(
            max_depth=4,
            learning_rate=0.05,
            n_estimators=500
        )

        model = model.train(X_train_final, Y_train)
        Y_train_predict = model.predict(X_train_final).reshape(-1)

        # =================================================
        # 5. æ¸¬è©¦è³‡æ–™ï¼šæ”¹æˆã€ŒçœŸæ­£è‡ªå›æ­¸ã€æ¨è«–ï¼ˆåªçœ‹è‡ªå·±å‰ä¸€æ ¼é æ¸¬ï¼‰
        # =================================================
        if use_autoreg:
            print("âš™ æ¸¬è©¦éšæ®µä½¿ç”¨ã€è‡ªå›æ­¸æ¨è«–ã€ï¼šPrevDepth = å‰ä¸€æ™‚é–“æ­¥æ¨¡å‹é æ¸¬å€¼ï¼ˆé¦–ç­† = 0ï¼‰")

            num_test = len(Y_test_raw)
            Y_pred_roll = np.zeros(num_test, dtype=np.float32)

            # æ¸¬è©¦äº‹ä»¶åœ¨ã€Œæ•´é«”åºåˆ—ã€ä¸­çš„èµ·é» index
            start_idx_global = split_boundary

            # ç¬¬ä¸€ç­† PrevDepth = 0
            prev_pred = 0.0

            for i_local in range(num_test):
                idx_global = start_idx_global + i_local

                # è©²ç­†çš„åŸºç¤ç‰¹å¾µ
                x_base = X_base_flat[idx_global]  # (D_base,)

                # æŠŠä¸Šä¸€æ™‚é–“æ­¥çš„é æ¸¬å€¼æ¥åˆ°æœ€å¾Œ
                x_with_prev = np.concatenate(
                    [x_base, np.array([prev_pred], dtype=np.float32)],
                    axis=0
                )  # (D_base+1,)

                # ç”¨è¨“ç·´æ™‚çš„ min/max æ­£è¦åŒ–
                x_final = x_with_prev.reshape(1, -1)
                y_hat = model.predict(x_final)[0]

                Y_pred_roll[i_local] = y_hat

                # æ›´æ–°ä¸‹ä¸€æ­¥ PrevDepth
                prev_pred = y_hat

            Y_predict = Y_pred_roll

        else:
            # æ²’é–‹è‡ªå›æ­¸å°±å–®ç´”ä¸€æ¬¡æ€§é æ¸¬ï¼ˆå…¨éƒ¨ test ä¸€æ¬¡ä¸Ÿé€²å»ï¼‰
            X_test_with_prev = X_test_base
            X_test_final = X_test_with_prev
            Y_predict = model.predict(X_test_final).reshape(-1)


        # =================================================
        # 6. è³‡æ–™å¾Œè™•ç†ï¼ˆè² å€¼æ”¹æˆ 0ï¼‰
        # =================================================
        obv_train = dp.convert_negative_to_zero(Y_train)
        est_train = dp.convert_negative_to_zero(Y_train_predict)
        obv_test  = dp.convert_negative_to_zero(Y_test)
        est_test  = dp.convert_negative_to_zero(Y_predict)

        RES_train.append([obv_train, est_train])
        RES_test.append([obv_test, est_test])

        # =================================================
        # 7. ç•«åœ–
        # =================================================
        if not os.path.exists(OUTPUT_FOLDER):
            os.makedirs(OUTPUT_FOLDER, exist_ok=True)
            print(f"Created directory: {OUTPUT_FOLDER}")
        else:
            print(f"Directory already exists: {OUTPUT_FOLDER}")

        if not os.path.exists(HYDROGRAPH_FOLDER):
            os.makedirs(HYDROGRAPH_FOLDER, exist_ok=True)
            print(f"Created directory: {HYDROGRAPH_FOLDER}")
        else:
            print(f"Directory already exists: {HYDROGRAPH_FOLDER}")

        if not os.path.exists(SCATTER_PLOT_FOLDER):
            os.makedirs(SCATTER_PLOT_FOLDER, exist_ok=True)
            print(f"Created directory: {SCATTER_PLOT_FOLDER}")
        else:
            print(f"Directory already exists: {SCATTER_PLOT_FOLDER}")

        fig_names = ['Hydrograph', 'Scatter plot']
        fig_folders = {
            'Hydrograph': HYDROGRAPH_FOLDER,
            'Scatter plot': SCATTER_PLOT_FOLDER
        }

        pltUT.draw_all(fig_names, fig_folders, ev_idx, obv_train, est_train, obv_test, est_test)

        # =================================================
        # 8. è¨˜æ†¶é«”æ¸…ç†ï¼ˆç°¡å–®ç‰ˆï¼šåª gc.collectï¼Œä¸äº‚ del æœªå®£å‘Šè®Šæ•¸ï¼‰
        # =================================================
        gc.collect()

        process = psutil.Process(os.getpid())
        print(f"ğŸ§  ç›®å‰è¨˜æ†¶é«”ä½¿ç”¨ï¼š{process.memory_info().rss / 1024 ** 2:.2f} MB")

    # å›å‚³ã€Œç¬¬ä¸€æŠ˜ã€çš„ Yï¼ˆå°æ‡‰ boundaries[0]ï¼‰ï¼Œçµ¦ get_eventWithMaxVal ä½¿ç”¨
    return Y_first_fold, boundaries, RES_train, RES_test, events, event_orders




# ================== RunModel.py æœ€åº•éƒ¨æ–°å¢ ==================

import data_processor as dp
from my_models import My_XGBoost

def export_final_xgb_ar_weights(SD_FILE, WEIGHTS_ROOT, delta_t, use_autoreg=True):
    """
    ä½¿ç”¨å…¨éƒ¨äº‹ä»¶è³‡æ–™è¨“ç·´ XGBoost_ARï¼Œä¸¦è¼¸å‡ºéƒ¨ç½²ç”¨æ¬Šé‡
    è¼¸å‡ºæ ¼å¼ï¼š
      WEIGHTS_ROOT/T{delta_t}_model.bin
    """

    print("  â–¶ Final training with all events")

    events = dp.load_data(SD_FILE)

    X_all = []
    y_all = []

    for ev in events:
        df = ev.copy()
        X_rain = df.iloc[:, :-1].astype(np.float32)
        y = df.iloc[:, -1].astype(np.float32)

        if use_autoreg:
            prev = y.shift(1).fillna(0.0).astype(np.float32)
            X_ev = X_rain.copy()
            X_ev["PrevDepth"] = prev.values
        else:
            X_ev = X_rain

        X_all.append(X_ev.values)
        y_all.append(y.values)

    X = np.concatenate(X_all, axis=0)
    y = np.concatenate(y_all, axis=0).reshape(-1)

    model = My_XGBoost(
        max_depth=4,
        learning_rate=0.05,
        n_estimators=800
    )
    model.train(X, y)

    out_path = os.path.join(WEIGHTS_ROOT, f"T{delta_t}_model.bin")
    model.save(out_path)

    print("  ğŸ’¾ Saved:", out_path)
